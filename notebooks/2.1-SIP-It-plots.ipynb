{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078025ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from typing import List, Any\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c23dfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp1 = \"../results/ALL_complete_meaningful_2.csv\"\n",
    "exp2 = \"../results/ALL_complete_meaningful.csv\"\n",
    "exp3 = \"../results/Baseline_20_meaningful.csv\"\n",
    "exp4 = \"../results/Baseline_20_random.csv\"\n",
    "exp5 = \"../results/SGD_20_random.csv\"\n",
    "exp6 = \"../results/SGD_complete_meaningful.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1532fdab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(exp1)\n",
    "df2 = pd.read_csv(exp2)\n",
    "df3 = pd.read_csv(exp3)\n",
    "df4 = pd.read_csv(exp4)\n",
    "df5 = pd.read_csv(exp5)\n",
    "df6 = pd.read_csv(exp6)\n",
    "\n",
    "df1['dataset_type'] = 'meaningful'\n",
    "df2['dataset_type'] = 'meaningful'\n",
    "\n",
    "df3['optimizer'] = 'baseline'\n",
    "df4['optimizer'] = 'baseline'\n",
    "\n",
    "df3['dataset_type'] = 'meaningful'\n",
    "df4['dataset_type'] = 'random'\n",
    "\n",
    "df5['dataset_type'] = 'random'\n",
    "df6['dataset_type'] = 'meaningful'\n",
    "\n",
    "df = pd.concat([df1, df2, df3, df4, df5, df6], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8126cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_statistics(\n",
    "    df: pd.DataFrame, \n",
    "    column_name: str = \"timesteps\", \n",
    "    indices: List[int] = [10],\n",
    "    reduce: str = 'mean'\n",
    "):\n",
    "    assert column_name in [\"timesteps\", \"times\"], \"Choises for `column_name`: ['timesteps', 'times'].\"\n",
    "    \n",
    "    reduction = (lambda x: np.mean(x)) if reduce == 'mean' else (lambda x: np.sum(x))\n",
    "\n",
    "    column = df[column_name]\n",
    "    scores = column.apply(lambda x: list(float(i) for i in x.split(\"_\")))\n",
    "\n",
    "    scores = [\n",
    "        scores.apply(lambda x: reduction(x[:i + 1]))\n",
    "        for i in indices\n",
    "    ]\n",
    "\n",
    "    return [\n",
    "        (x.mean(), x.std())\n",
    "        for x in scores\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed1ffbb",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79861c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from utils.constants import COLORS\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import shutil\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from utils.metrics import _agg_metric\n",
    "\n",
    "# Define the custom color palette\n",
    "\n",
    "# Define a custom color palette (Slate Gray replaces Eggshell)\n",
    "color_dict = {\n",
    "    \"Slate Gray\": \"#708090\",\n",
    "    \"Burnt sienna\": \"#e07a5f\",\n",
    "    \"Delft Blue\": \"#3d405b\",\n",
    "    \"Cambridge blue\": \"#81b29a\",\n",
    "    \"Sunset\": \"#f2cc8f\",\n",
    "    \"Eggshell\": \"#f4f1de\",\n",
    "}\n",
    "# Styles order: darker hues first\n",
    "STYLES = [\n",
    "    color_dict[\"Delft Blue\"],\n",
    "    color_dict[\"Burnt sienna\"],\n",
    "    color_dict[\"Cambridge blue\"],\n",
    "    color_dict[\"Sunset\"],\n",
    "    color_dict[\"Slate Gray\"],\n",
    "]\n",
    "\n",
    "# Default discrete colormap from STYLES\n",
    "# Continuous colormap from Burnt sienna to Eggshell\n",
    "\n",
    "DARK_BURNTSIENNA = \"#b3614c\"  # ~20% darker than #e07a5f\n",
    "\n",
    "DEFAULT_CMAP = LinearSegmentedColormap.from_list(\n",
    "    \"burnt_sienna_to_eggshell\",\n",
    "    [color_dict[\"Eggshell\"], color_dict[\"Burnt sienna\"], color_dict[\"Burnt sienna\"], color_dict[\"Burnt sienna\"], DARK_BURNTSIENNA, DARK_BURNTSIENNA, DARK_BURNTSIENNA],\n",
    "    N=256\n",
    ")\n",
    "\n",
    "\n",
    "# Check for LaTeX availability and configure text rendering\n",
    "usetex_available = shutil.which('latex') is not None\n",
    "plt.rcParams['text.usetex'] = usetex_available\n",
    "if not usetex_available:\n",
    "    plt.rcParams['text.usetex'] = False\n",
    "    print(\"Warning: LaTeX not found, falling back to Matplotlib mathtext.\")\n",
    "\n",
    "# Global style settings\n",
    "plt.rcParams.update({\n",
    "    \"font.family\": \"serif\",\n",
    "    \"axes.titlesize\": 24,\n",
    "    \"axes.labelsize\": 20,\n",
    "    \"xtick.labelsize\": 20,\n",
    "    \"ytick.labelsize\": 20,\n",
    "    \"legend.fontsize\": 16,\n",
    "})\n",
    "\n",
    "def _rename(name: str, rename_dict: dict = None) -> str:\n",
    "    \"\"\"\n",
    "    Rename a metric name based on a provided dictionary.\n",
    "    \"\"\"\n",
    "    return rename_dict.get(name, name) if rename_dict else name\n",
    "\n",
    "\n",
    "def plot_metrics(\n",
    "    metrics,\n",
    "    fill_between: bool = True,\n",
    "    rename: dict = None,\n",
    "    xlabel: str = None,\n",
    "    ylabel: str = None,\n",
    "    title: str = None,\n",
    "    figsize: tuple = (12, 8),\n",
    "    integer_xticks: bool = False,\n",
    "    y_logscale: bool = False,\n",
    "    xticks: list = None,\n",
    "    yticks: list = None\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot aggregated metrics per layer with the custom palette and styling.\n",
    "    \"\"\"\n",
    "    agg_metrics = {m: _agg_metric(metrics, m) for m in metrics}\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "\n",
    "    for i, (metric_name, (mean, std)) in enumerate(agg_metrics.items()):\n",
    "        x = np.arange(len(mean))\n",
    "        color = STYLES[i % len(STYLES)]\n",
    "        if fill_between:\n",
    "            ax.fill_between(x, mean - std, mean + std, alpha=0.2, color=color)\n",
    "        ax.plot(\n",
    "            x, mean,\n",
    "            label=_rename(metric_name, rename) if _rename(metric_name, rename) != 'SGD' else 'GD',\n",
    "            color=color,\n",
    "            marker='o',\n",
    "            markersize=8,\n",
    "            linewidth=2\n",
    "        )\n",
    "\n",
    "    ax.set_xlabel(xlabel, fontsize=20)\n",
    "    ax.set_ylabel(ylabel, fontsize=20)\n",
    "    if title:\n",
    "        ax.set_title(title, fontsize=24)\n",
    "    if y_logscale:\n",
    "        ax.set_yscale('log')\n",
    "\n",
    "    ax.tick_params(axis='x', labelsize=16)\n",
    "    ax.tick_params(axis='y', labelsize=20)\n",
    "    if integer_xticks:\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels([str(i + 1) for i in x], fontsize=16)\n",
    "    if xticks is not None:\n",
    "        ax.set_xticks(xticks)\n",
    "    if yticks is not None:\n",
    "        ax.set_yticks(yticks)\n",
    "\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['bottom'].set_position(('outward', 5))\n",
    "    ax.spines['left'].set_position(('outward', 5))\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "\n",
    "    ax.legend(\n",
    "        loc='upper center',\n",
    "        bbox_to_anchor=(0.5, -0.15),\n",
    "        ncol=len(agg_metrics),\n",
    "        frameon=False,\n",
    "        fontsize=14\n",
    "    )\n",
    "\n",
    "    fig.subplots_adjust(left=0.15, right=0.85, bottom=0.25, top=0.9)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_heatmap(\n",
    "    df,\n",
    "    title: str = None,\n",
    "    xlabel: str = None,\n",
    "    ylabel: str = None,\n",
    "    cmap=None,\n",
    "    figsize: tuple = (12, 8),\n",
    "    y_ticks: List[Any] = []\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Plot a styled heatmap using the custom discrete palette.\n",
    "    \"\"\"\n",
    "    import seaborn as sns\n",
    "\n",
    "    # Use default STYLES colormap if none provided\n",
    "    cmap_to_use = cmap if cmap is not None else DEFAULT_CMAP\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    heatmap = sns.heatmap(\n",
    "        df,\n",
    "        annot=True,\n",
    "        fmt=\".1f\",\n",
    "        cmap=cmap_to_use,\n",
    "        annot_kws={\"fontsize\": 16, \"fontfamily\": \"serif\"},\n",
    "        cbar_kws={\"label\": ylabel}\n",
    "    )\n",
    "\n",
    "    cbar = heatmap.collections[0].colorbar\n",
    "    cbar.ax.yaxis.label.set_size(20)\n",
    "    cbar.ax.tick_params(labelsize=20)\n",
    "\n",
    "    if title:\n",
    "        ax.set_title(title, fontsize=24)\n",
    "    if xlabel:\n",
    "        ax.set_xlabel(xlabel, fontsize=20)\n",
    "    if ylabel:\n",
    "        ax.set_ylabel(ylabel, fontsize=20)\n",
    "\n",
    "\n",
    "    if y_ticks:\n",
    "        # ax.set_yticks([x + 1 for x in range(len(y_ticks))])\n",
    "        ax.set_yticklabels([str(i + 1) for i in y_ticks], fontsize=16)\n",
    "\n",
    "    ax.tick_params(axis='x', labelsize=16)\n",
    "    ax.tick_params(axis='y', labelsize=16)\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha='right')\n",
    "\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['bottom'].set_position(('outward', 5))\n",
    "    ax.spines['left'].set_position(('outward', 5))\n",
    "\n",
    "    fig.subplots_adjust(left=0.15, right=0.85, bottom=0.3, top=0.9)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_bar_with_error_bars_log(\n",
    "    data: dict[str, tuple[float, float]],\n",
    "    xlabel: str = None,\n",
    "    ylabel: str = \"Mean Timesteps\",\n",
    "    title: str = \"Optimizer Comparison\",\n",
    "    figsize: tuple = (12, 8)\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Plot a bar chart with error bars on a log y-axis in publication-quality style.\n",
    "    \"\"\"\n",
    "    names = list(data.keys())\n",
    "    means = [data[name][0] for name in names]\n",
    "    stds = [data[name][1] for name in names]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    colors = STYLES[:len(names)]\n",
    "    ax.bar(\n",
    "        names,\n",
    "        means,\n",
    "        yerr=stds,\n",
    "        capsize=5,\n",
    "        color=colors\n",
    "    )\n",
    "\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_xlabel(xlabel, fontsize=20)\n",
    "    ax.set_ylabel(ylabel, fontsize=20)\n",
    "    ax.set_title(title, fontsize=24)\n",
    "\n",
    "    ax.tick_params(axis='x', labelsize=16)\n",
    "    ax.tick_params(axis='y', labelsize=20)\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha='right')\n",
    "\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['bottom'].set_position(('outward', 5))\n",
    "    ax.spines['left'].set_position(('outward', 5))\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "\n",
    "    fig.subplots_adjust(left=0.15, right=0.85, bottom=0.3, top=0.9)\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4b850b",
   "metadata": {},
   "source": [
    "### Experiments 8.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817e0c8b",
   "metadata": {},
   "source": [
    "E8.1 show how the convergence rate change when you change the gradient step-size \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e5fb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_type = 'meaningful'\n",
    "optimizer = 'SGD'\n",
    "layer = 6\n",
    "learning_rates = df[df['optimizer'] == optimizer]['learning_rate'].unique().tolist()\n",
    "\n",
    "# filter dataframe based on dataset_type and optimizer \n",
    "df_exp_8_1 = df[(df['dataset_type'] == dataset_type) & (df['optimizer'] == optimizer) & (df['layer'] == layer)]\n",
    "df_exp_8_1.head()\n",
    "\n",
    "df_exp_8_1_results = {\n",
    "    x: compute_statistics(df_exp_8_1[df_exp_8_1['learning_rate'] == x], indices=range(20), column_name='timesteps', reduce=\"sum\")\n",
    "    for x in learning_rates\n",
    "}\n",
    "\n",
    "plot_metrics(\n",
    "    metrics=df_exp_8_1_results,\n",
    "    xlabel=\"Length of string n (in tokens)\",\n",
    "    ylabel=\"# iterations t (mean ± std)\",\n",
    "    title=\"\", integer_xticks=True,\n",
    "    y_logscale=True\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cefe035",
   "metadata": {},
   "source": [
    "Average accross all the 8 layers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f6fa16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now compute the same quantities but averaged for all layers from 1 to 8\n",
    "df_exp_8_1_all_layers = df[(df['dataset_type'] == dataset_type) & (df['optimizer'] == optimizer)]\n",
    "df_exp_8_1_all_layers_results = {\n",
    "    x: compute_statistics(df_exp_8_1_all_layers[df_exp_8_1_all_layers['learning_rate'] == x], indices=range(20), column_name='timesteps', reduce=\"sum\")\n",
    "    for x in learning_rates\n",
    "}\n",
    "plot_metrics(\n",
    "    metrics=df_exp_8_1_all_layers_results,\n",
    "    xlabel=\"Length of string n (in tokens)\",\n",
    "    ylabel=\"# iterations t (mean ± std)\",\n",
    "    title=\"\", integer_xticks=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1cfd12",
   "metadata": {},
   "source": [
    "We also keep printing this interesting outlier in the last layer hinting something for larger models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75b93a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_type = 'meaningful'\n",
    "optimizer = 'SGD'\n",
    "layer = 8\n",
    "learning_rates = df[df['optimizer'] == optimizer]['learning_rate'].unique().tolist()\n",
    "\n",
    "# filter dataframe based on dataset_type and optimizer \n",
    "df_exp_8_1 = df[(df['dataset_type'] == dataset_type) & (df['optimizer'] == optimizer) & (df['layer'] == layer)]\n",
    "df_exp_8_1.head()\n",
    "\n",
    "df_exp_8_1_results = {\n",
    "    x: compute_statistics(df_exp_8_1[df_exp_8_1['learning_rate'] == x], indices=range(20), column_name='timesteps',reduce=\"sum\")\n",
    "    for x in learning_rates\n",
    "}\n",
    "\n",
    "plot_metrics(\n",
    "    metrics=df_exp_8_1_results,\n",
    "    xlabel=\"Length of string n (in tokens)\",\n",
    "    ylabel=\"# iterations t (mean ± std)\",\n",
    "    title=\"\", integer_xticks=True\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0be7218",
   "metadata": {},
   "source": [
    "### Experiment 8.2 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc880cc",
   "metadata": {},
   "source": [
    "E8.2 show how the convergence rate change when you change the first order algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1815623",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_type = 'meaningful'\n",
    "optimizers = [\"SGD\", \"Adam\", \"AdamW\", \"RMSprop\"]\n",
    "layer = 4\n",
    "learning_rates = 1\n",
    "\n",
    "# filter dataframe based on dataset_type and optimizer\n",
    "df_exp_8_2 = df[(df['dataset_type'] == dataset_type) & (df['layer'] == layer) & (df['learning_rate'] == learning_rates)]\n",
    "\n",
    "df_exp_8_2_results = {\n",
    "    x: compute_statistics(df_exp_8_2[df_exp_8_2['optimizer'] == x], indices=range(20), column_name='timesteps', reduce=\"sum\")\n",
    "    for x in optimizers\n",
    "}\n",
    "plot_metrics(\n",
    "    metrics=df_exp_8_2_results,\n",
    "    xlabel=\"Length of string n (in tokens)\",\n",
    "    ylabel=\"# iterations t (mean ± std)\",\n",
    "    title=\"\", integer_xticks=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909927cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_type = 'meaningful'\n",
    "optimizers = [\"SGD\", \"Adam\", \"AdamW\", \"RMSprop\"]\n",
    "layer = 4\n",
    "learning_rates = 0.01\n",
    "\n",
    "# filter dataframe based on dataset_type and optimizer\n",
    "df_exp_8_2 = df[(df['dataset_type'] == dataset_type) & (df['layer'] == layer) & (df['learning_rate'] == learning_rates)]\n",
    "\n",
    "df_exp_8_2_results = {\n",
    "    x: compute_statistics(df_exp_8_2[df_exp_8_2['optimizer'] == x], indices=range(20), column_name='timesteps', reduce=\"sum\")\n",
    "    for x in optimizers\n",
    "}\n",
    "plot_metrics(\n",
    "    metrics=df_exp_8_2_results,\n",
    "    xlabel=\"Length of string n (in tokens)\",\n",
    "    ylabel=\"# iterations t (mean ± std)\",\n",
    "    title=\"\", integer_xticks=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d23b55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"optimizer\"] == \"baseline\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7dd9e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_type = 'meaningful'\n",
    "optimizers = [\"SGD\", \"Adam\", \"AdamW\", \"RMSprop\", \"baseline\"]\n",
    "layer = 4\n",
    "learning_rates = 1\n",
    "df_exp_8_2 = df[(df['dataset_type'] == dataset_type) & (df['layer'] == layer) & (df['learning_rate'] == learning_rates)]\n",
    "df_exp_8_2_results = {\n",
    "    x: compute_statistics(df_exp_8_2[df_exp_8_2['optimizer'] == x], indices=range(20), column_name='times', reduce=\"mean\")\n",
    "    for x in optimizers\n",
    "}\n",
    "baseline = df_exp_8_2_results[\"baseline\"][19] # mean, std\n",
    "SGD = df_exp_8_2_results[\"SGD\"][19] # mean, std\n",
    "Adam = df_exp_8_2_results[\"Adam\"][19] # mean, std\n",
    "AdamW = df_exp_8_2_results[\"AdamW\"][19] # mean, std\n",
    "RMSprop = df_exp_8_2_results[\"RMSprop\"][19] # mean, std\n",
    "\n",
    "# represent them as a bar plot with names on the x-axis and mean values on the y-axis, with error bars for std\n",
    "\n",
    "def plot_bar_with_error_bars_log(\n",
    "    data: dict[str, tuple[float, float]],\n",
    "    xlabel: str = None,\n",
    "    ylabel: str = \"Mean Timesteps\",\n",
    "    title: str = \"Optimizer Comparison\",\n",
    "    figsize: tuple = (12, 8)\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Plot a bar chart with error bars on a log y-axis in publication-quality style.\n",
    "\n",
    "    Args:\n",
    "        data:   Mapping from label to (mean, std) tuple.\n",
    "        xlabel: Label for the x-axis.\n",
    "        ylabel: Label for the y-axis.\n",
    "        title:  Title of the plot.\n",
    "        figsize: Figure size (width, height).\n",
    "    \"\"\"\n",
    "    names = list(data.keys())\n",
    "    means = [data[name][0] for name in names]\n",
    "    stds = [data[name][1] for name in names]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    # Use the same STYLES palette\n",
    "    colors = STYLES[:len(names)]\n",
    "    bars = ax.bar(\n",
    "        names,\n",
    "        means,\n",
    "        # yerr=stds,\n",
    "        capsize=5,\n",
    "        color=colors\n",
    "    )\n",
    "\n",
    "    ax.set_yscale('log')\n",
    "    # Labels and title\n",
    "    ax.set_xlabel(xlabel, fontsize=20)\n",
    "    ax.set_ylabel(ylabel, fontsize=20)\n",
    "    ax.set_title(title, fontsize=24)\n",
    "\n",
    "    # Tick customization\n",
    "    ax.tick_params(axis='x', labelsize=16)\n",
    "    ax.tick_params(axis='y', labelsize=20)\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha='right')\n",
    "\n",
    "    # Clean spines\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['bottom'].set_position(('outward', 5))\n",
    "    ax.spines['left'].set_position(('outward', 5))\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "\n",
    "    # Adjust layout to center axes and prevent clipping\n",
    "    fig.subplots_adjust(left=0.15, right=0.85, bottom=0.3, top=0.9)\n",
    "    plt.show()\n",
    "\n",
    "plot_bar_with_error_bars_log(\n",
    "    data={\n",
    "        \"SGD\": SGD,\n",
    "        \"Adam\": Adam,\n",
    "        \"AdamW\": AdamW,\n",
    "        \"RMSprop\": RMSprop,\n",
    "        \"Baseline\": baseline\n",
    "    },\n",
    "    title=\"Optimizer Comparison at Layer 4 with Learning Rate 1\",\n",
    "    ylabel=\"Mean Time (s) (log scale)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bf1a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_type = 'meaningful'\n",
    "optimizers = [\"SGD\", \"Adam\", \"AdamW\", \"RMSprop\", \"baseline\"]\n",
    "layer = 4\n",
    "# learning_rates = 0.01\n",
    "learning_rates = 1.0\n",
    "df_exp_8_2 = df[(df['dataset_type'] == dataset_type) & (df['layer'] == layer) & (df['learning_rate'] == learning_rates)]\n",
    "df_exp_8_2_results = {\n",
    "    x: compute_statistics(df_exp_8_2[df_exp_8_2['optimizer'] == x], indices=range(20), column_name='timesteps', reduce=\"sum\")\n",
    "    for x in optimizers\n",
    "}\n",
    "baseline = df_exp_8_2_results[\"baseline\"][19] # mean, std\n",
    "SGD = df_exp_8_2_results[\"SGD\"][19] # mean, std\n",
    "Adam = df_exp_8_2_results[\"Adam\"][19] # mean, std\n",
    "AdamW = df_exp_8_2_results[\"AdamW\"][19] # mean, std\n",
    "RMSprop = df_exp_8_2_results[\"RMSprop\"][19] # mean, std\n",
    "\n",
    "plot_bar_with_error_bars_log(\n",
    "    data={\n",
    "        \"SGD\": SGD,\n",
    "        \"Adam\": Adam,\n",
    "        \"AdamW\": AdamW,\n",
    "        \"RMSprop\": RMSprop,\n",
    "        \"Baseline\": baseline\n",
    "    },\n",
    "    # title=\"Optimizer Comparison at Layer 4 with Learning Rate 1\"\n",
    "    title='',\n",
    "    ylabel=\"Mean Timesteps (log scale)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574d7620",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_lr_grouped_by_optimizer(\n",
    "    data: dict[float, dict[str, tuple[float, float]]],\n",
    "    optimizers: list[str],\n",
    "    learning_rates: list[float],\n",
    "    xlabel: str = \"Learning Rate\",\n",
    "    ylabel: str = \"Mean Timesteps (log scale)\",\n",
    "    title: str = \"\",\n",
    "    figsize: tuple = (12, 8)\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Plot a grouped bar chart: for each learning rate (group), bars for each optimizer.\n",
    "    Colors differentiate optimizers.\n",
    "    \"\"\"\n",
    "    n_lrs = len(learning_rates)\n",
    "    n_opts = len(optimizers)\n",
    "    bar_width = 0.8 / n_opts\n",
    "    x = np.arange(n_lrs)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "\n",
    "    # One color per optimizer\n",
    "    colours = STYLES[:n_opts]\n",
    "\n",
    "    for i, opt in enumerate(optimizers):\n",
    "        # heights and errors for this optimizer across all LRs\n",
    "        means = [data[lr][opt][0] for lr in learning_rates]\n",
    "        stds  = [data[lr][opt][1] for lr in learning_rates]\n",
    "        # horizontal offset for bars of this optimizer\n",
    "        offset = (i - (n_opts - 1) / 2) * bar_width\n",
    "        ax.bar(\n",
    "            x + offset,\n",
    "            means,\n",
    "            width=bar_width,\n",
    "            # yerr=stds,\n",
    "            capsize=5,\n",
    "            label=opt if opt != 'SGD' else 'GD',\n",
    "            color=colours[i]\n",
    "        )\n",
    "\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_xlabel(xlabel, fontsize=20)\n",
    "    ax.set_ylabel(ylabel, fontsize=20)\n",
    "    ax.set_title(title, fontsize=24)\n",
    "\n",
    "    # set x-ticks to the center of each LR group\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels([f\"LR={lr}\" for lr in learning_rates], fontsize=16)\n",
    "    ax.tick_params(axis='y', labelsize=20)\n",
    "\n",
    "    # Legend shows optimizer mapping to color\n",
    "    ax.legend(title=\"Optimizer\", fontsize=16, title_fontsize=18)\n",
    "\n",
    "    # Clean spines\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['bottom'].set_position(('outward', 5))\n",
    "    ax.spines['left'].set_position(('outward', 5))\n",
    "    fig.subplots_adjust(left=0.15, right=0.85, bottom=0.25, top=0.9)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "# Prepare the data for two learning rates\n",
    "optimizers = [\"SGD\", \"Adam\", \"AdamW\", \"RMSprop\"]\n",
    "learning_rates = [1.0, 0.01]\n",
    "\n",
    "results_by_lr = {}\n",
    "for lr in learning_rates:\n",
    "    df_filtered = df[\n",
    "        (df['dataset_type'] == dataset_type) &\n",
    "        (df['layer'] == layer) &\n",
    "        (df['learning_rate'] == lr)\n",
    "    ]\n",
    "    stats = {\n",
    "        opt: compute_statistics(\n",
    "            df_filtered[df_filtered['optimizer'] == opt],\n",
    "            indices=range(20),\n",
    "            column_name='timesteps',\n",
    "            reduce=\"sum\"\n",
    "        )[19]\n",
    "        for opt in optimizers\n",
    "    }\n",
    "    results_by_lr[lr] = stats\n",
    "\n",
    "plot_lr_grouped_by_optimizer(\n",
    "    data=results_by_lr,\n",
    "    optimizers=optimizers,\n",
    "    learning_rates=learning_rates,\n",
    "    title=\"Optimizer Comparison by Learning Rate\",\n",
    "    ylabel=\"Mean Timesteps (log scale)\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1bac762",
   "metadata": {},
   "source": [
    "### Experiment 10.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f01465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# two lists, layer 4, sgd, random/meaningful, lr=1\n",
    "\n",
    "\n",
    "dataset_type = ['meaningful', 'random']\n",
    "learning_rate = 1.0\n",
    "optimizer = 'SGD'\n",
    "layer = 4\n",
    "\n",
    "df_exp10 = df[(df['learning_rate'] == learning_rate) & (df['optimizer'] == optimizer) & (df['layer'] == layer)]\n",
    "\n",
    "df_exp10_results = {\n",
    "    x: compute_statistics(df_exp10[df_exp10['dataset_type'] == x], indices=range(17), column_name='timesteps', reduce=\"mean\")\n",
    "    for x in dataset_type\n",
    "}\n",
    "\n",
    "plot_metrics(\n",
    "    metrics=df_exp10_results,\n",
    "    xlabel=\"Length of string n (in tokens)\",\n",
    "    ylabel=\"# iterations t (mean ± std)\",\n",
    "    title=\"\", integer_xticks=True,\n",
    "    # y_logscale=True\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd7e674",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exp10_results = {\n",
    "    x: compute_statistics(df_exp10[df_exp10['dataset_type'] == x], indices=range(20), column_name='timesteps', reduce=\"sum\")\n",
    "    for x in dataset_type\n",
    "}\n",
    "\n",
    "plot_metrics(\n",
    "    metrics=df_exp10_results,\n",
    "    xlabel=\"Length of string n (in tokens)\",\n",
    "    ylabel=\"# iterations t (mean ± std)\",\n",
    "    title=\"\", integer_xticks=True\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a1f22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_type = ['meaningful', 'random']\n",
    "learning_rate = 1.0\n",
    "optimizer = 'baseline'\n",
    "layer = 4\n",
    "\n",
    "df_exp10 = df[(df['learning_rate'] == learning_rate) & (df['optimizer'] == optimizer) & (df['layer'] == layer)]\n",
    "\n",
    "df_exp10_results = {\n",
    "    x: compute_statistics(df_exp10[df_exp10['dataset_type'] == x], indices=range(20), column_name='timesteps', reduce=\"mean\")\n",
    "    for x in dataset_type\n",
    "}\n",
    "\n",
    "plot_metrics(\n",
    "    metrics=df_exp10_results,\n",
    "    xlabel=\"Length of string n (in tokens)\",\n",
    "    ylabel=\"# iterations t (mean ± std)\",\n",
    "    title=\"\", integer_xticks=True\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01bed7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_type = 'random'\n",
    "learning_rate = 1.0\n",
    "optimizer = ['SGD', 'baseline']\n",
    "layer = 4\n",
    "\n",
    "df_exp10 = df[(df['learning_rate'] == learning_rate) & (df['dataset_type'] == dataset_type) & (df['layer'] == layer)]\n",
    "\n",
    "df_exp10_results = {\n",
    "    x: compute_statistics(df_exp10[df_exp10['optimizer'] == x], indices=range(20), column_name='timesteps', reduce=\"mean\")\n",
    "    for x in optimizer\n",
    "}\n",
    "\n",
    "plot_metrics(\n",
    "    metrics=df_exp10_results,\n",
    "    xlabel=\"Length of string n (in tokens)\",\n",
    "    ylabel=\"# iterations t (mean ± std)\",\n",
    "    title=\"\", integer_xticks=True,\n",
    "    y_logscale=False\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776b2913",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exp10_results = {\n",
    "    x: compute_statistics(df_exp10[df_exp10['optimizer'] == x], indices=range(20), column_name='times', reduce=\"sum\")\n",
    "    for x in optimizer\n",
    "}\n",
    "\n",
    "plot_metrics(\n",
    "    metrics=df_exp10_results,\n",
    "    xlabel=\"Length of string n (in tokens)\",\n",
    "    ylabel=\"Time (seconds) t (mean ± std)\",\n",
    "    title=\"\", integer_xticks=True,\n",
    "    y_logscale=True\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649a3433",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exp10_results = {\n",
    "    x: compute_statistics(df_exp10[df_exp10['optimizer'] == x], indices=range(20), column_name='timesteps', reduce=\"sum\")\n",
    "    for x in optimizer\n",
    "}\n",
    "\n",
    "plot_metrics(\n",
    "    metrics=df_exp10_results,\n",
    "    xlabel=\"Length of string n (in tokens)\",\n",
    "    ylabel=\"# iterations t (mean ± std)\",\n",
    "    title=\"\", integer_xticks=True,\n",
    "    y_logscale=True\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01baddd4",
   "metadata": {},
   "source": [
    "### Experiment 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926d9c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "dataset_type = 'meaningful'\n",
    "learning_rate = 1.0\n",
    "optimizer = 'SGD'\n",
    "layer = np.arange(7) + 1\n",
    "\n",
    "indices = np.array([5, 12, 15])\n",
    "\n",
    "df_exp10 = df[(df['learning_rate'] == learning_rate) & (df['dataset_type'] == dataset_type) & (df['optimizer'] == optimizer)]\n",
    "\n",
    "df_exp10_results = {\n",
    "    x: compute_statistics(df_exp10[df_exp10['layer'] == x], indices=indices, column_name='timesteps', reduce=\"sum\")\n",
    "    for x in layer\n",
    "}\n",
    "\n",
    "summary = {}\n",
    "for key, values in df_exp10_results.items():\n",
    "    for i, (x, y) in enumerate(values):\n",
    "        if i not in summary:\n",
    "            summary[i] = {}\n",
    "        summary[i][key] = y\n",
    "\n",
    "df111 = pd.DataFrame(summary).T.sort_index()\n",
    "   \n",
    "plot_heatmap(\n",
    "    df111,\n",
    "    # title=\"Heatmap of Y Values by Index and Key\",\n",
    "    xlabel=\"Layer\",\n",
    "    ylabel=\"Length of string n (in tokens)\",\n",
    "    # cmap=\"YlGnBu\"\n",
    "    y_ticks=list(indices)\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "itallm2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
