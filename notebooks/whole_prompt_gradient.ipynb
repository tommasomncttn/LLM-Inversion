{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d810884",
   "metadata": {},
   "source": [
    "# whole prompt descent\n",
    "\n",
    "Can we descent on the whole prompt at once?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5e0aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no need to restart kernel after code (in the imported files) changes\n",
    "%load_ext autoreload\n",
    "%autoreload 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3d7896",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from utils import compute_last_token_embedding_grad, extract_hidden_states_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5f3d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"roneneldan/TinyStories-1M\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"roneneldan/TinyStories-1M\", output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255851be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.methods import invert_whole_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b0a902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "from utils.plotting import plot_loss\n",
    "\n",
    "\n",
    "def test_inversion_on_layers(prompt, model, tokenizer, n_iterations=1000, lr=0.01):\n",
    "    \"\"\"\n",
    "    Test inversion on all layers of the model.\n",
    "\n",
    "    Args:\n",
    "        prompt (str): The input prompt to invert.\n",
    "        model: The language model.\n",
    "        tokenizer: The tokenizer for the model.\n",
    "    \"\"\"\n",
    "    print(f\"Inverting prompt: {prompt}\")\n",
    "    n_layers = len(model.transformer.h)\n",
    "    losses_list = []\n",
    "    distances_list = []\n",
    "    for i in range(n_layers):\n",
    "        layer_idx = i\n",
    "        reconstructed_prompt, losses, times, steps, distances = invert_whole_prompt(\n",
    "            prompt, model, tokenizer, layer_idx, n_iterations=n_iterations, lr=lr\n",
    "        )\n",
    "        losses_list.append(losses)\n",
    "        distances_list.append(distances)\n",
    "        print(f\"Layer {layer_idx}: Reconstructed Prompt: {reconstructed_prompt}\")\n",
    "    return losses_list, distances_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22083cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"My name is george and I live in Greece.\"\n",
    "losses_list, distances_list = test_inversion_on_layers(prompt, model, tokenizer, n_iterations=1000, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d01e427",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(losses_list, title=\"Losses during inversion\", xlabel=\"Iteration\", ylabel=\"Loss\", log_scale=True)\n",
    "plot_loss(distances_list, title=\"Distances of the prompt embeddings\", xlabel=\"Iteration\", ylabel=\"Distance\", log_scale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f4b1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = \"my name is george and I live in Greece.\"\n",
    "prompt = \"\"\"\n",
    "According to all known laws of aviation,\n",
    "there is no way a bee should be able to fly.\n",
    "\n",
    "Its wings are too small to get its fat little body off the ground.\n",
    "The bee, of course, flies anyway\n",
    "because bees don’t care what humans think is impossible.\n",
    "\n",
    "Yellow, black. Yellow, black.\n",
    "Yellow, black. Yellow, black.\n",
    "Ooh, black and yellow!\n",
    "Let’s shake it up a little.\n",
    "\n",
    "Barry! Breakfast is ready!\n",
    "\n",
    "Coming!\n",
    "\n",
    "Hang on a second.\n",
    "Hello?\n",
    "\n",
    "Barry?\n",
    "Adam?\n",
    "\n",
    "Can you believe this is happening?\n",
    "I can’t. I’ll pick you up.\n",
    "\n",
    "Looking sharp.\n",
    "\"\"\"\n",
    "losses_list, distances_list = test_inversion_on_layers(prompt, model, tokenizer, n_iterations=1000, gamma=1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7622368c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(losses_list, title=\"Losses during inversion\", xlabel=\"Iteration\", ylabel=\"Loss\", log_scale=True)\n",
    "plot_loss(distances_list, title=\"Distances of the prompt embeddings\", xlabel=\"Iteration\", ylabel=\"Distance\", log_scale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b982853",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Here is my secrete key: b4e3cfe16a409f237a91c778e5f82b1493d546bc3adbd268cb346f8e2f55e72c. Do not share it with anyone!!!\"\n",
    "\n",
    "losses_list, distances_list = test_inversion_on_layers(prompt, model, tokenizer, n_iterations=1000, gamma=1e-1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
